{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd1bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv,SAGEConv,GCNConv,TransformerConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import DataLoader, Batch\n",
    "from torch.nn import Sequential, Linear, ReLU, LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98284ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd8c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples:  3826\n",
      "Test Samples:  1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khed-sofiane/anaconda3/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "train_data1 = UPFD(root=\".\", name=\"gossipcop\", feature=\"profile\", split=\"train\")\n",
    "test_data1 = UPFD(root=\".\", name=\"gossipcop\", feature=\"profile\", split=\"test\")\n",
    "print(\"Train Samples: \", len(test_data1))\n",
    "print(\"Test Samples: \", len(train_data1))\n",
    "test_loader1 = DataLoader(train_data1, batch_size=128, shuffle=False)\n",
    "#print(batch_idx)\n",
    "train_loader1 = DataLoader(test_data1, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dba6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples:  3826\n",
      "Test Samples:  1092\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "train_data2= UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\", split=\"train\")\n",
    "test_data2= UPFD(root=\".\", name=\"gossipcop\", feature=\"bert\", split=\"test\")\n",
    "print(\"Train Samples: \", len(test_data2))\n",
    "print(\"Test Samples: \", len(train_data2))\n",
    "test_loader2 = DataLoader(train_data2, batch_size=128, shuffle=False)\n",
    "train_loader2= DataLoader(test_data2, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e9626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads=2, dropout=0.01):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        self.attention = TransformerConv(in_channels, out_channels, heads=heads, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.attention(x, edge_index)\n",
    "        return F.relu(x)  # Apply ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c1f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformerModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, hidden_ch, out_channels, heads=2, dropout=0.01):\n",
    "        super(GraphTransformerModel, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        # Use TransformerLayer instead of TransformerConv directly\n",
    "        self.conv1 = TransformerLayer(in_channels, hidden_ch, heads, dropout)\n",
    "        self.conv2 = TransformerLayer(hidden_ch * heads, hidden_ch, heads,dropout)\n",
    "        self.conv3 = TransformerLayer(hidden_ch * heads, hidden_channels,1,dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)  # First Transformer layer\n",
    "        h = self.conv2(h, edge_index)  # Second Transformer layer\n",
    "        h = self.conv3(h, edge_index)  # Third Transformer layer\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCoAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_channels1, hidden_channels2, num_heads,dropout_rate=0.01):\n",
    "        super(MultiHeadCoAttentionLayer, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_channels1 = hidden_channels1\n",
    "        self.hidden_channels2 = hidden_channels2\n",
    "\n",
    "        # Define separate attention weights for each head\n",
    "        self.query1 = nn.Linear(hidden_channels1, hidden_channels1 * num_heads, bias=False)\n",
    "        self.key1 = nn.Linear(hidden_channels1, hidden_channels1 * num_heads, bias=False)\n",
    "        self.value1 = nn.Linear(hidden_channels1, hidden_channels1 * num_heads, bias=False)\n",
    "\n",
    "        self.query2 = nn.Linear(hidden_channels2, hidden_channels2 * num_heads, bias=False)\n",
    "        self.key2 = nn.Linear(hidden_channels2, hidden_channels2 * num_heads, bias=False)\n",
    "        self.value2 = nn.Linear(hidden_channels2, hidden_channels2 * num_heads, bias=False)\n",
    "\n",
    "        # Output linear layers\n",
    "        self.out1 = nn.Linear(hidden_channels1 * num_heads, hidden_channels1)\n",
    "        self.out2 = nn.Linear(hidden_channels2 * num_heads, hidden_channels2)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        x1: Tensor of shape [batch_size, hidden_channels1]\n",
    "        x2: Tensor of shape [batch_size, hidden_channels2]\n",
    "        \"\"\"\n",
    "        # Multi-head queries, keys, and values\n",
    "        Q1 = self.query1(x1).view(-1, self.num_heads, self.hidden_channels1)\n",
    "        K2 = self.key2(x2).view(-1, self.num_heads, self.hidden_channels2)\n",
    "        V2 = self.value2(x2).view(-1, self.num_heads, self.hidden_channels2)\n",
    "\n",
    "        Q2 = self.query2(x2).view(-1, self.num_heads, self.hidden_channels2)\n",
    "        K1 = self.key1(x1).view(-1, self.num_heads, self.hidden_channels1)\n",
    "        V1 = self.value1(x1).view(-1, self.num_heads, self.hidden_channels1)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attn_scores1 = torch.matmul(Q1, K2.transpose(-2, -1)) / (self.hidden_channels2 ** 0.5)\n",
    "        attn_weights1 = F.softmax(attn_scores1, dim=-1)\n",
    "        # Apply dropout to attention weights\n",
    "        attn_weights11 = self.dropout(attn_weights1)\n",
    "        attended_x1 = torch.matmul(attn_weights11, V2)\n",
    "\n",
    "        attn_scores2 = torch.matmul(Q2, K1.transpose(-2, -1)) / (self.hidden_channels1 ** 0.5)\n",
    "        attn_weights2 = F.softmax(attn_scores2, dim=-1)\n",
    "        # Apply dropout to attention weights\n",
    "        attn_weights22 = self.dropout(attn_weights2)\n",
    "        attended_x2 = torch.matmul(attn_weights2, V1)\n",
    "\n",
    "        # Concatenate heads and project back to the original dimension\n",
    "        attended_x1 = attended_x1.view(-1, self.num_heads * self.hidden_channels1)\n",
    "        attended_x2 = attended_x2.view(-1, self.num_heads * self.hidden_channels2)\n",
    "\n",
    "        out_x1 = self.out1(attended_x1) + x1  # Residual connection\n",
    "        out_x2 = self.out2(attended_x2) + x2  # Residual connection\n",
    "\n",
    "        return out_x1, out_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62e5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSAGE(nn.Module):\n",
    "    def __init__(self, in_channels1, in_channels2, hidden_channels1, hidden_channels2, out_channels,heads=2, dropout=0.01):\n",
    "        super(CombinedSAGE, self).__init__()\n",
    "        self.model1 = GraphTransformerModel(in_channels1, hidden_channels, hidden_channels1, out_channels,heads,dropout)\n",
    "        self.model2 = GraphTransformerModel(in_channels2, hidden_channels, hidden_channels2, out_channels,heads,dropout)\n",
    "        \n",
    "        \n",
    "        # Multi-Head Co-Attention Layer\n",
    "        self.co_attention = MultiHeadCoAttentionLayer(hidden_channels, hidden_channels, num_heads)\n",
    "\n",
    "        #self.co_attention = CoAttentionLayer(hidden_channels, hidden_channels)\n",
    "        self.fc = nn.Linear(hidden_channels + hidden_channels, out_channels)  # Fusion FC layer\n",
    "        #self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x1, x2, edge_index1, edge_index2, batch_idx):\n",
    "        # Pass inputs through individual models\n",
    "        t1 = self.model1(x1, edge_index1)\n",
    "        t2 = self.model2(x2, edge_index2)\n",
    "       \n",
    "        # Apply co-attention\n",
    "        t1, t2 = self.co_attention(t1, t2)\n",
    "        #print(t1.shape)\n",
    "        #print(t2.shape)\n",
    "\n",
    "        # Fuse features and pool\n",
    "        fused_features = torch.cat((t1, t2), dim=-1)\n",
    "        flatten = global_max_pool(fused_features, batch=batch_idx)\n",
    "        out = self.fc(flatten)\n",
    "        #out1 = self.logsoftmax(out)\n",
    "        return torch.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecbc1d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedSAGE(\n",
       "  (model1): GraphTransformerModel(\n",
       "    (conv1): TransformerLayer(\n",
       "      (attention): TransformerConv(10, 26, heads=2)\n",
       "    )\n",
       "    (conv2): TransformerLayer(\n",
       "      (attention): TransformerConv(52, 26, heads=2)\n",
       "    )\n",
       "    (conv3): TransformerLayer(\n",
       "      (attention): TransformerConv(52, 100, heads=1)\n",
       "    )\n",
       "  )\n",
       "  (model2): GraphTransformerModel(\n",
       "    (conv1): TransformerLayer(\n",
       "      (attention): TransformerConv(768, 200, heads=2)\n",
       "    )\n",
       "    (conv2): TransformerLayer(\n",
       "      (attention): TransformerConv(400, 200, heads=2)\n",
       "    )\n",
       "    (conv3): TransformerLayer(\n",
       "      (attention): TransformerConv(400, 100, heads=1)\n",
       "    )\n",
       "  )\n",
       "  (co_attention): MultiHeadCoAttentionLayer(\n",
       "    (query1): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (key1): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (value1): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (query2): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (key2): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (value2): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (out1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (out2): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (dropout): Dropout(p=0.01, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels1 = train_data1.num_features # Number of input features for dataset 1\n",
    "hidden_channels1 = 26\n",
    "hidden_channels2 = 200\n",
    "hidden_channels = 100 # Number of hidden features for dataset 1\n",
    "attention_dim=90\n",
    "out_channels = 1 # Number of output features for dataset 1\n",
    "in_channels2 = train_data2.num_features # Number of input features for dataset 2\n",
    "num_heads=1\n",
    "dropout2 = 0.6 # Dropout probability for dataset 2\n",
    "negative_slope2 = 0.2 # Negative slope for LeakyReLU for dataset 2\n",
    "#combined_model = CombinedGAT(model1, model2)\n",
    "CombinedSAGE(in_channels1, in_channels2, hidden_channels1, hidden_channels2, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58464d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score,roc_auc_score, precision_score, recall_score\n",
    "combined_model=CombinedSAGE(in_channels1, in_channels2, hidden_channels1, hidden_channels2, out_channels)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_fnc = torch.nn.BCELoss()\n",
    "#optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "#num_epochs = 20\n",
    "def metrics(preds, gts):\n",
    "    probs = torch.cat(preds).cpu().numpy()  # raw sigmoid outputs\n",
    "    preds_bin = torch.round(torch.cat(preds)).cpu().numpy()\n",
    "    gts = torch.cat(gts).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(gts, preds_bin)\n",
    "    f1 = f1_score(gts, preds_bin, zero_division=0)\n",
    "    prec = precision_score(gts, preds_bin, zero_division=0)\n",
    "    rec = recall_score(gts, preds_bin, zero_division=0)\n",
    "\n",
    "    if len(set(gts)) < 2:\n",
    "        print(\"Cannot compute AUC: only one class present.\")\n",
    "        auc = None\n",
    "    else:\n",
    "        auc = roc_auc_score(gts, probs)  # Correct input: probs, not preds_bin\n",
    "\n",
    "    return acc, f1, auc, prec, rec\n",
    "#print(f'Test Loss: {running_loss2/len(train_loader1.dataset)}')\n",
    "#for epoch in range(num_epochs):\n",
    "def train(epoch):\n",
    "    combined_model.train()\n",
    "    running_loss = 0.0\n",
    "    for data1, data2 in zip(train_loader1, train_loader2):\n",
    "        #combined_batch = Batch.from_data_list([data1, data2])\n",
    "        optimizer.zero_grad()\n",
    "        x1, edge_index1, y1,batch1 = data1.x, data1.edge_index, data1.y,data1.batch\n",
    "        x2, edge_index2, y2,batch2 = data2.x, data2.edge_index, data2.y,data2.batch\n",
    "        \n",
    "        out1 = combined_model(x1, x2, edge_index1, edge_index2,batch1)\n",
    "        \n",
    "        loss1 = loss_fnc(out1.squeeze(), y1.to(torch.float))\n",
    "        \n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss1.item()\n",
    "    return running_loss/len(train_loader1.dataset)\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader1.dataset)}')\n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(epoch):\n",
    "    combined_model.eval()\n",
    "    running_loss2 = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    #with torch.no_grad():\n",
    "    for data1, data2 in zip(test_loader1, test_loader2):\n",
    "        \n",
    "        x1, edge_index1, x2, edge_index2, batch11 = data1.x, data1.edge_index, data2.x,data1.edge_index, data1.batch\n",
    "        \n",
    "        xt1, edge_indext1, yt1,batcht1 = data1.x, data1.edge_index, data1.y,data1.batch\n",
    "        xt2, edge_indext2, yt2,batcht2 = data2.x, data2.edge_index, data2.y,data2.batch\n",
    "        outt1= combined_model(xt1, xt2, edge_indext1, edge_indext2, batcht1)\n",
    "        losst1 = loss_fnc(outt1.squeeze(), yt1.to(torch.float))\n",
    "\n",
    "        running_loss2 += losst1.item()\n",
    "        all_preds.append(outt1.squeeze())\n",
    "        #print(all_preds.shape)\n",
    "        all_labels.append(yt1.to(torch.float))\n",
    "        \n",
    "    accuracy, f1,auc,prec,rec = metrics(all_preds, all_labels)\n",
    "    return running_loss2 / len(test_loader1.dataset), accuracy, f1,auc,prec,rec\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddadc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 |  TestAcc: 0.8471 |TestF1: 0.8579 | Test_auc: 0.9534 |Test_prec: 0.7875|Test_rec: 0.9421\n",
      "Epoch: 01 |  TestAcc: 0.9460 |TestF1: 0.9447 | Test_auc: 0.9858 |Test_prec: 0.9474|Test_rec: 0.9421\n",
      "Epoch: 02 |  TestAcc: 0.9560 |TestF1: 0.9557 | Test_auc: 0.9878 |Test_prec: 0.9435|Test_rec: 0.9682\n",
      "Epoch: 03 |  TestAcc: 0.9606 |TestF1: 0.9599 | Test_auc: 0.9903 |Test_prec: 0.9572|Test_rec: 0.9626\n",
      "Epoch: 04 |  TestAcc: 0.9643 |TestF1: 0.9634 | Test_auc: 0.9921 |Test_prec: 0.9662|Test_rec: 0.9607\n",
      "Epoch: 05 |  TestAcc: 0.9670 |TestF1: 0.9660 | Test_auc: 0.9931 |Test_prec: 0.9771|Test_rec: 0.9551\n",
      "Epoch: 06 |  TestAcc: 0.9625 |TestF1: 0.9612 | Test_auc: 0.9930 |Test_prec: 0.9732|Test_rec: 0.9495\n",
      "Epoch: 07 |  TestAcc: 0.9643 |TestF1: 0.9631 | Test_auc: 0.9937 |Test_prec: 0.9751|Test_rec: 0.9514\n",
      "Epoch: 08 |  TestAcc: 0.9725 |TestF1: 0.9720 | Test_auc: 0.9945 |Test_prec: 0.9702|Test_rec: 0.9738\n",
      "Epoch: 09 |  TestAcc: 0.9588 |TestF1: 0.9591 | Test_auc: 0.9927 |Test_prec: 0.9329|Test_rec: 0.9869\n",
      "Epoch: 10 |  TestAcc: 0.9588 |TestF1: 0.9591 | Test_auc: 0.9928 |Test_prec: 0.9329|Test_rec: 0.9869\n",
      "Epoch: 11 |  TestAcc: 0.9597 |TestF1: 0.9599 | Test_auc: 0.9921 |Test_prec: 0.9376|Test_rec: 0.9832\n",
      "Epoch: 12 |  TestAcc: 0.9661 |TestF1: 0.9661 | Test_auc: 0.9932 |Test_prec: 0.9478|Test_rec: 0.9850\n",
      "Epoch: 13 |  TestAcc: 0.9661 |TestF1: 0.9659 | Test_auc: 0.9937 |Test_prec: 0.9527|Test_rec: 0.9794\n",
      "Epoch: 14 |  TestAcc: 0.9689 |TestF1: 0.9683 | Test_auc: 0.9940 |Test_prec: 0.9647|Test_rec: 0.9720\n",
      "Epoch: 15 |  TestAcc: 0.9615 |TestF1: 0.9605 | Test_auc: 0.9929 |Test_prec: 0.9677|Test_rec: 0.9533\n",
      "Epoch: 16 |  TestAcc: 0.9707 |TestF1: 0.9703 | Test_auc: 0.9948 |Test_prec: 0.9632|Test_rec: 0.9776\n",
      "Epoch: 17 |  TestAcc: 0.9652 |TestF1: 0.9643 | Test_auc: 0.9942 |Test_prec: 0.9698|Test_rec: 0.9589\n",
      "Epoch: 18 |  TestAcc: 0.9533 |TestF1: 0.9505 | Test_auc: 0.9950 |Test_prec: 0.9879|Test_rec: 0.9159\n",
      "Epoch: 19 |  TestAcc: 0.9634 |TestF1: 0.9634 | Test_auc: 0.9939 |Test_prec: 0.9428|Test_rec: 0.9850\n",
      "Epoch: 20 |  TestAcc: 0.9670 |TestF1: 0.9667 | Test_auc: 0.9936 |Test_prec: 0.9578|Test_rec: 0.9757\n",
      "Epoch: 21 |  TestAcc: 0.9670 |TestF1: 0.9658 | Test_auc: 0.9949 |Test_prec: 0.9826|Test_rec: 0.9495\n",
      "Epoch: 22 |  TestAcc: 0.9689 |TestF1: 0.9680 | Test_auc: 0.9951 |Test_prec: 0.9735|Test_rec: 0.9626\n",
      "Epoch: 23 |  TestAcc: 0.9643 |TestF1: 0.9632 | Test_auc: 0.9952 |Test_prec: 0.9733|Test_rec: 0.9533\n",
      "Epoch: 24 |  TestAcc: 0.9625 |TestF1: 0.9614 | Test_auc: 0.9941 |Test_prec: 0.9696|Test_rec: 0.9533\n",
      "Epoch: 25 |  TestAcc: 0.9634 |TestF1: 0.9625 | Test_auc: 0.9941 |Test_prec: 0.9644|Test_rec: 0.9607\n",
      "Epoch: 26 |  TestAcc: 0.9670 |TestF1: 0.9661 | Test_auc: 0.9945 |Test_prec: 0.9734|Test_rec: 0.9589\n",
      "Epoch: 27 |  TestAcc: 0.9625 |TestF1: 0.9608 | Test_auc: 0.9943 |Test_prec: 0.9824|Test_rec: 0.9402\n",
      "Epoch: 28 |  TestAcc: 0.9606 |TestF1: 0.9591 | Test_auc: 0.9944 |Test_prec: 0.9767|Test_rec: 0.9421\n",
      "Epoch: 29 |  TestAcc: 0.9670 |TestF1: 0.9662 | Test_auc: 0.9940 |Test_prec: 0.9716|Test_rec: 0.9607\n",
      "Epoch: 30 |  TestAcc: 0.9597 |TestF1: 0.9581 | Test_auc: 0.9930 |Test_prec: 0.9767|Test_rec: 0.9402\n",
      "Epoch: 31 |  TestAcc: 0.9615 |TestF1: 0.9605 | Test_auc: 0.9936 |Test_prec: 0.9677|Test_rec: 0.9533\n",
      "Epoch: 32 |  TestAcc: 0.9414 |TestF1: 0.9371 | Test_auc: 0.9945 |Test_prec: 0.9876|Test_rec: 0.8916\n",
      "Epoch: 33 |  TestAcc: 0.9560 |TestF1: 0.9537 | Test_auc: 0.9950 |Test_prec: 0.9860|Test_rec: 0.9234\n",
      "Epoch: 34 |  TestAcc: 0.9505 |TestF1: 0.9481 | Test_auc: 0.9936 |Test_prec: 0.9762|Test_rec: 0.9215\n",
      "Epoch: 35 |  TestAcc: 0.9698 |TestF1: 0.9690 | Test_auc: 0.9935 |Test_prec: 0.9754|Test_rec: 0.9626\n",
      "Epoch: 36 |  TestAcc: 0.9570 |TestF1: 0.9548 | Test_auc: 0.9937 |Test_prec: 0.9841|Test_rec: 0.9271\n",
      "Epoch: 37 |  TestAcc: 0.9560 |TestF1: 0.9538 | Test_auc: 0.9923 |Test_prec: 0.9822|Test_rec: 0.9271\n",
      "Epoch: 38 |  TestAcc: 0.9625 |TestF1: 0.9608 | Test_auc: 0.9935 |Test_prec: 0.9824|Test_rec: 0.9402\n",
      "Epoch: 39 |  TestAcc: 0.9744 |TestF1: 0.9740 | Test_auc: 0.9944 |Test_prec: 0.9686|Test_rec: 0.9794\n",
      "Epoch: 40 |  TestAcc: 0.9698 |TestF1: 0.9690 | Test_auc: 0.9941 |Test_prec: 0.9736|Test_rec: 0.9645\n",
      "Epoch: 41 |  TestAcc: 0.9734 |TestF1: 0.9731 | Test_auc: 0.9945 |Test_prec: 0.9668|Test_rec: 0.9794\n",
      "Epoch: 42 |  TestAcc: 0.9707 |TestF1: 0.9704 | Test_auc: 0.9946 |Test_prec: 0.9598|Test_rec: 0.9813\n",
      "Epoch: 43 |  TestAcc: 0.9725 |TestF1: 0.9716 | Test_auc: 0.9945 |Test_prec: 0.9828|Test_rec: 0.9607\n",
      "Epoch: 44 |  TestAcc: 0.9634 |TestF1: 0.9617 | Test_auc: 0.9944 |Test_prec: 0.9862|Test_rec: 0.9383\n",
      "Epoch: 45 |  TestAcc: 0.9570 |TestF1: 0.9546 | Test_auc: 0.9945 |Test_prec: 0.9880|Test_rec: 0.9234\n",
      "Epoch: 46 |  TestAcc: 0.9734 |TestF1: 0.9727 | Test_auc: 0.9936 |Test_prec: 0.9810|Test_rec: 0.9645\n",
      "Epoch: 47 |  TestAcc: 0.9679 |TestF1: 0.9671 | Test_auc: 0.9942 |Test_prec: 0.9735|Test_rec: 0.9607\n",
      "Epoch: 48 |  TestAcc: 0.9597 |TestF1: 0.9578 | Test_auc: 0.9939 |Test_prec: 0.9842|Test_rec: 0.9327\n",
      "Epoch: 49 |  TestAcc: 0.9698 |TestF1: 0.9695 | Test_auc: 0.9937 |Test_prec: 0.9597|Test_rec: 0.9794\n",
      "Epoch: 50 |  TestAcc: 0.9744 |TestF1: 0.9741 | Test_auc: 0.9946 |Test_prec: 0.9651|Test_rec: 0.9832\n",
      "Epoch: 51 |  TestAcc: 0.9725 |TestF1: 0.9719 | Test_auc: 0.9947 |Test_prec: 0.9755|Test_rec: 0.9682\n",
      "Epoch: 52 |  TestAcc: 0.9707 |TestF1: 0.9699 | Test_auc: 0.9947 |Test_prec: 0.9754|Test_rec: 0.9645\n",
      "Epoch: 53 |  TestAcc: 0.9698 |TestF1: 0.9690 | Test_auc: 0.9948 |Test_prec: 0.9736|Test_rec: 0.9645\n",
      "Epoch: 54 |  TestAcc: 0.9734 |TestF1: 0.9729 | Test_auc: 0.9946 |Test_prec: 0.9720|Test_rec: 0.9738\n",
      "Epoch: 55 |  TestAcc: 0.9707 |TestF1: 0.9704 | Test_auc: 0.9942 |Test_prec: 0.9598|Test_rec: 0.9813\n",
      "Epoch: 56 |  TestAcc: 0.9744 |TestF1: 0.9740 | Test_auc: 0.9948 |Test_prec: 0.9686|Test_rec: 0.9794\n",
      "Epoch: 57 |  TestAcc: 0.9725 |TestF1: 0.9722 | Test_auc: 0.9942 |Test_prec: 0.9633|Test_rec: 0.9813\n",
      "Epoch: 58 |  TestAcc: 0.9744 |TestF1: 0.9737 | Test_auc: 0.9951 |Test_prec: 0.9792|Test_rec: 0.9682\n",
      "Epoch: 59 |  TestAcc: 0.9762 |TestF1: 0.9757 | Test_auc: 0.9947 |Test_prec: 0.9775|Test_rec: 0.9738\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(60):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss, test_acc, test_f1,test_auc,test_prec,test_rec = test(epoch)\n",
    "    print(f'Epoch: {epoch:02d} |  TestAcc: {test_acc:.4f} |'\n",
    "          f'TestF1: {test_f1:.4f} | Test_auc: {test_auc:.4f} |Test_prec: {test_prec:.4f}|Test_rec: {test_rec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f86a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd3105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
