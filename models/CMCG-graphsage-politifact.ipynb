{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd1bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv,SAGEConv,GCNConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import DataLoader, Batch\n",
    "from torch.nn import Linear, LogSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98284ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd8c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples:  221\n",
      "Test Samples:  62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khed-sofiane/anaconda3/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "train_data1 = UPFD(root=\".\", name=\"politifact\", feature=\"profile\", split=\"train\")\n",
    "test_data1 = UPFD(root=\".\", name=\"politifact\", feature=\"profile\", split=\"test\")\n",
    "print(\"Train Samples: \", len(test_data1))\n",
    "print(\"Test Samples: \", len(train_data1))\n",
    "test_loader1 = DataLoader(train_data1, batch_size=64, shuffle=False)\n",
    "#print(batch_idx)\n",
    "train_loader1 = DataLoader(test_data1, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dba6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples:  221\n",
      "Test Samples:  62\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import UPFD\n",
    "train_data2= UPFD(root=\".\", name=\"politifact\", feature=\"bert\", split=\"train\")\n",
    "test_data2= UPFD(root=\".\", name=\"politifact\", feature=\"bert\", split=\"test\")\n",
    "print(\"Train Samples: \", len(test_data2))\n",
    "print(\"Test Samples: \", len(train_data2))\n",
    "test_loader2 = DataLoader(train_data2, batch_size=64, shuffle=False)\n",
    "train_loader2= DataLoader(test_data2, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e9626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGELayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SAGELayer, self).__init__()\n",
    "        self.attention = SAGEConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.attention(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c1f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels,hidden_ch, out_channels):\n",
    "        super(GAT, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = SAGELayer(in_channels, hidden_ch)\n",
    "        self.conv2 = SAGELayer(hidden_ch, hidden_ch)\n",
    "        self.conv3 = SAGELayer(hidden_ch, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #print(x.shape)\n",
    "        h = F.elu(self.conv1(x, edge_index))\n",
    "        #print(h.shape)\n",
    "        h = F.elu(self.conv2(h, edge_index))\n",
    "        h = F.elu(self.conv3(h, edge_index))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCoAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_channels1, hidden_channels2, num_heads,dropout_rate=0.005):\n",
    "        super(MultiHeadCoAttentionLayer, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.hidden_channels1 = hidden_channels1\n",
    "        self.hidden_channels2 = hidden_channels2\n",
    "\n",
    "        # Define separate attention weights for each head\n",
    "        self.query1 = nn.Linear(hidden_channels1, hidden_channels1 * num_heads, bias=False)\n",
    "        self.key1 = nn.Linear(hidden_channels1, hidden_channels1 * num_heads, bias=False)\n",
    "        self.value1 = nn.Linear(hidden_channels1, hidden_channels1 * num_heads, bias=False)\n",
    "\n",
    "        self.query2 = nn.Linear(hidden_channels2, hidden_channels2 * num_heads, bias=False)\n",
    "        self.key2 = nn.Linear(hidden_channels2, hidden_channels2 * num_heads, bias=False)\n",
    "        self.value2 = nn.Linear(hidden_channels2, hidden_channels2 * num_heads, bias=False)\n",
    "\n",
    "        # Output linear layers\n",
    "        self.out1 = nn.Linear(hidden_channels1 * num_heads, hidden_channels1)\n",
    "        self.out2 = nn.Linear(hidden_channels2 * num_heads, hidden_channels2)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        x1: Tensor of shape [batch_size, hidden_channels1]\n",
    "        x2: Tensor of shape [batch_size, hidden_channels2]\n",
    "        \"\"\"\n",
    "        # Multi-head queries, keys, and values\n",
    "        Q1 = self.query1(x1).view(-1, self.num_heads, self.hidden_channels1)\n",
    "        K2 = self.key2(x2).view(-1, self.num_heads, self.hidden_channels2)\n",
    "        V2 = self.value2(x2).view(-1, self.num_heads, self.hidden_channels2)\n",
    "\n",
    "        Q2 = self.query2(x2).view(-1, self.num_heads, self.hidden_channels2)\n",
    "        K1 = self.key1(x1).view(-1, self.num_heads, self.hidden_channels1)\n",
    "        V1 = self.value1(x1).view(-1, self.num_heads, self.hidden_channels1)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        attn_scores1 = torch.matmul(Q1, K2.transpose(-2, -1)) / (self.hidden_channels2 ** 0.5)\n",
    "        attn_weights1 = F.softmax(attn_scores1, dim=-1)\n",
    "        # Apply dropout to attention weights\n",
    "        attn_weights11 = self.dropout(attn_weights1)\n",
    "        attended_x1 = torch.matmul(attn_weights11, V2)\n",
    "\n",
    "        attn_scores2 = torch.matmul(Q2, K1.transpose(-2, -1)) / (self.hidden_channels1 ** 0.5)\n",
    "        attn_weights2 = F.softmax(attn_scores2, dim=-1)\n",
    "        # Apply dropout to attention weights\n",
    "        attn_weights22 = self.dropout(attn_weights2)\n",
    "        attended_x2 = torch.matmul(attn_weights2, V1)\n",
    "\n",
    "        # Concatenate heads and project back to the original dimension\n",
    "        attended_x1 = attended_x1.view(-1, self.num_heads * self.hidden_channels1)\n",
    "        attended_x2 = attended_x2.view(-1, self.num_heads * self.hidden_channels2)\n",
    "\n",
    "        out_x1 = self.out1(attended_x1) + x1  # Residual connection\n",
    "        out_x2 = self.out2(attended_x2) + x2  # Residual connection\n",
    "\n",
    "        return out_x1, out_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62e5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSAGE(nn.Module):\n",
    "    def __init__(self, in_channels1, in_channels2, hidden_channels1, hidden_channels2, out_channels):\n",
    "        super(CombinedSAGE, self).__init__()\n",
    "        self.model1 = GAT(in_channels1, hidden_channels, hidden_channels1, out_channels)\n",
    "        self.model2 = GAT(in_channels2, hidden_channels, hidden_channels2, out_channels)\n",
    "        \n",
    "        \n",
    "        # Multi-Head Co-Attention Layer\n",
    "        self.co_attention = MultiHeadCoAttentionLayer(hidden_channels, hidden_channels, num_heads)\n",
    "\n",
    "        #self.co_attention = CoAttentionLayer(hidden_channels, hidden_channels)\n",
    "        self.fc = nn.Linear(hidden_channels + hidden_channels, out_channels)  # Fusion FC layer\n",
    "        #self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x1, x2, edge_index1, edge_index2, batch_idx):\n",
    "        # Pass inputs through individual models\n",
    "        t1 = self.model1(x1, edge_index1)\n",
    "        t2 = self.model2(x2, edge_index2)\n",
    "        \n",
    "        # Apply co-attention\n",
    "        t1, t2 = self.co_attention(t1, t2)\n",
    "       \n",
    "        # Fuse features and pool\n",
    "        fused_features = torch.cat((t1, t2), dim=-1)\n",
    "        flatten = global_max_pool(fused_features, batch=batch_idx)\n",
    "        out = self.fc(flatten)\n",
    "        #out1 = self.logsoftmax(out)\n",
    "        return torch.sigmoid(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecbc1d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedSAGE(\n",
       "  (model1): GAT(\n",
       "    (conv1): SAGELayer(\n",
       "      (attention): SAGEConv(10, 10, aggr=mean)\n",
       "    )\n",
       "    (conv2): SAGELayer(\n",
       "      (attention): SAGEConv(10, 10, aggr=mean)\n",
       "    )\n",
       "    (conv3): SAGELayer(\n",
       "      (attention): SAGEConv(10, 8, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (model2): GAT(\n",
       "    (conv1): SAGELayer(\n",
       "      (attention): SAGEConv(768, 30, aggr=mean)\n",
       "    )\n",
       "    (conv2): SAGELayer(\n",
       "      (attention): SAGEConv(30, 30, aggr=mean)\n",
       "    )\n",
       "    (conv3): SAGELayer(\n",
       "      (attention): SAGEConv(30, 8, aggr=mean)\n",
       "    )\n",
       "  )\n",
       "  (co_attention): MultiHeadCoAttentionLayer(\n",
       "    (query1): Linear(in_features=8, out_features=16, bias=False)\n",
       "    (key1): Linear(in_features=8, out_features=16, bias=False)\n",
       "    (value1): Linear(in_features=8, out_features=16, bias=False)\n",
       "    (query2): Linear(in_features=8, out_features=16, bias=False)\n",
       "    (key2): Linear(in_features=8, out_features=16, bias=False)\n",
       "    (value2): Linear(in_features=8, out_features=16, bias=False)\n",
       "    (out1): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (out2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (dropout): Dropout(p=0.005, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels1 = train_data1.num_features # Number of input features for dataset 1\n",
    "hidden_channels1 = 10\n",
    "hidden_channels2 = 30\n",
    "hidden_channels = 8 # Number of hidden features for dataset 1\n",
    "attention_dim=90\n",
    "out_channels = 1 # Number of output features for dataset 1\n",
    "in_channels2 = train_data2.num_features # Number of input features for dataset 2\n",
    "num_heads=2\n",
    "dropout2 = 0.6 # Dropout probability for dataset 2\n",
    "negative_slope2 = 0.2 # Negative slope for LeakyReLU for dataset 2\n",
    "CombinedSAGE(in_channels1, in_channels2, hidden_channels1, hidden_channels2, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58464d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score,roc_auc_score, precision_score, recall_score\n",
    "combined_model=CombinedSAGE(in_channels1, in_channels2, hidden_channels1, hidden_channels2, out_channels)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_fnc = torch.nn.BCELoss()\n",
    "#optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(combined_model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "#num_epochs = 20\n",
    "def metrics(preds, gts):\n",
    "    probs = torch.cat(preds).cpu().numpy()  # raw sigmoid outputs\n",
    "    preds_bin = torch.round(torch.cat(preds)).cpu().numpy()\n",
    "    gts = torch.cat(gts).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(gts, preds_bin)\n",
    "    f1 = f1_score(gts, preds_bin, zero_division=0)\n",
    "    prec = precision_score(gts, preds_bin, zero_division=0)\n",
    "    rec = recall_score(gts, preds_bin, zero_division=0)\n",
    "\n",
    "    if len(set(gts)) < 2:\n",
    "        print(\"Cannot compute AUC: only one class present.\")\n",
    "        auc = None\n",
    "    else:\n",
    "        auc = roc_auc_score(gts, probs)  # Correct input: probs, not preds_bin\n",
    "\n",
    "    return acc, f1, auc, prec, rec\n",
    "#print(f'Test Loss: {running_loss2/len(train_loader1.dataset)}')\n",
    "#for epoch in range(num_epochs):\n",
    "def train(epoch):\n",
    "    combined_model.train()\n",
    "    running_loss = 0.0\n",
    "    for data1, data2 in zip(train_loader1, train_loader2):\n",
    "        #combined_batch = Batch.from_data_list([data1, data2])\n",
    "        optimizer.zero_grad()\n",
    "        x1, edge_index1, y1,batch1 = data1.x, data1.edge_index, data1.y,data1.batch\n",
    "        x2, edge_index2, y2,batch2 = data2.x, data2.edge_index, data2.y,data2.batch\n",
    "        out1 = combined_model(x1, x2, edge_index1, edge_index2,batch1)\n",
    "        loss1 = loss_fnc(out1.squeeze(), y1.to(torch.float))\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss1.item()\n",
    "    return running_loss/len(train_loader1.dataset)\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader1.dataset)}')\n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(epoch):\n",
    "    combined_model.eval()\n",
    "    running_loss2 = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    #with torch.no_grad():\n",
    "    for data1, data2 in zip(test_loader1, test_loader2):\n",
    "        x1, edge_index1, x2, edge_index2, batch11 = data1.x, data1.edge_index, data2.x,data1.edge_index, data1.batch\n",
    "        \n",
    "        xt1, edge_indext1, yt1,batcht1 = data1.x, data1.edge_index, data1.y,data1.batch\n",
    "        xt2, edge_indext2, yt2,batcht2 = data2.x, data2.edge_index, data2.y,data2.batch\n",
    "        outt1= combined_model(xt1, xt2, edge_indext1, edge_indext2, batcht1)\n",
    "        losst1 = loss_fnc(outt1.squeeze(), yt1.to(torch.float))\n",
    "        running_loss2 += losst1.item()\n",
    "        all_preds.append(outt1.squeeze())\n",
    "        #print(all_preds.shape)\n",
    "        all_labels.append(yt1.to(torch.float))\n",
    "        \n",
    "    accuracy, f1,auc,prec,rec = metrics(all_preds, all_labels)\n",
    "    return running_loss2 / len(test_loader1.dataset), accuracy, f1,auc,prec,rec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddadc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00 |  TestAcc: 0.5806 |TestF1: 0.0000 | Test_auc: 0.6100 |Test_prec: 0.0000|Test_rec: 0.0000\n",
      "Epoch: 01 |  TestAcc: 0.4194 |TestF1: 0.5909 | Test_auc: 0.7682 |Test_prec: 0.4194|Test_rec: 1.0000\n",
      "Epoch: 02 |  TestAcc: 0.4516 |TestF1: 0.6047 | Test_auc: 0.8600 |Test_prec: 0.4333|Test_rec: 1.0000\n",
      "Epoch: 03 |  TestAcc: 0.7581 |TestF1: 0.7619 | Test_auc: 0.9263 |Test_prec: 0.6486|Test_rec: 0.9231\n",
      "Epoch: 04 |  TestAcc: 0.9032 |TestF1: 0.8846 | Test_auc: 0.9498 |Test_prec: 0.8846|Test_rec: 0.8846\n",
      "Epoch: 05 |  TestAcc: 0.8548 |TestF1: 0.8421 | Test_auc: 0.9583 |Test_prec: 0.7742|Test_rec: 0.9231\n",
      "Epoch: 06 |  TestAcc: 0.9194 |TestF1: 0.9057 | Test_auc: 0.9615 |Test_prec: 0.8889|Test_rec: 0.9231\n",
      "Epoch: 07 |  TestAcc: 0.9032 |TestF1: 0.8889 | Test_auc: 0.9701 |Test_prec: 0.8571|Test_rec: 0.9231\n",
      "Epoch: 08 |  TestAcc: 0.9032 |TestF1: 0.8889 | Test_auc: 0.9754 |Test_prec: 0.8571|Test_rec: 0.9231\n",
      "Epoch: 09 |  TestAcc: 0.9194 |TestF1: 0.9091 | Test_auc: 0.9744 |Test_prec: 0.8621|Test_rec: 0.9615\n",
      "Epoch: 10 |  TestAcc: 0.9032 |TestF1: 0.8889 | Test_auc: 0.9722 |Test_prec: 0.8571|Test_rec: 0.9231\n",
      "Epoch: 11 |  TestAcc: 0.9032 |TestF1: 0.8929 | Test_auc: 0.9733 |Test_prec: 0.8333|Test_rec: 0.9615\n",
      "Epoch: 12 |  TestAcc: 0.9194 |TestF1: 0.9091 | Test_auc: 0.9722 |Test_prec: 0.8621|Test_rec: 0.9615\n",
      "Epoch: 13 |  TestAcc: 0.9032 |TestF1: 0.8929 | Test_auc: 0.9712 |Test_prec: 0.8333|Test_rec: 0.9615\n",
      "Epoch: 14 |  TestAcc: 0.9516 |TestF1: 0.9434 | Test_auc: 0.9712 |Test_prec: 0.9259|Test_rec: 0.9615\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss, test_acc, test_f1,test_auc,test_prec,test_rec = test(epoch)\n",
    "    print(f'Epoch: {epoch:02d} |  TestAcc: {test_acc:.4f} |'\n",
    "          f'TestF1: {test_f1:.4f} | Test_auc: {test_auc:.4f} |Test_prec: {test_prec:.4f}|Test_rec: {test_rec:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f86a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd3105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
